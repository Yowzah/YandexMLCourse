{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метрики качества классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import precision_score as precision\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import f1_score as f_measure\n",
    "\n",
    "from sklearn.metrics import roc_auc_score as roc\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_task(): #пункт 3 задания\n",
    "    \n",
    "    train = []\n",
    "    with open('classification.csv') as file:\n",
    "        reader = csv.reader(file, delimiter = ',')\n",
    "        for row in reader:\n",
    "            train.append(row)\n",
    "            \n",
    "    train = np.array(train)\n",
    "    \n",
    "    train_true = train[1:,0]\n",
    "    train_true = [int(i) for i in train_true]\n",
    "    \n",
    "    train_pred = train[1:,1]\n",
    "    train_pred = [int(i) for i in train_pred]\n",
    "    \n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for i in range(len(train_true)):\n",
    "        if train_true[i] == train_pred[i] and train_true[i] == 1:\n",
    "            tp += 1\n",
    "        if train_true[i] == train_pred[i] and train_true[i] == 0:\n",
    "            tn += 1\n",
    "        if train_true[i] != train_pred[i] and train_true[i] == 1:\n",
    "            fn += 1\n",
    "        if train_true[i] != train_pred[i] and train_true[i] == 0:\n",
    "            fp += 1\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Actual positive' : [tp, fp],\n",
    "        'Actual negative' : [tn, fn]\n",
    "    }, index=['Predicted Positive', 'Predicted Negative']);\n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    accuracy_result = accuracy(train_true, train_pred) #доля верно угаданных\n",
    "    precision_result = precision(train_true, train_pred) #точность\n",
    "    recall_result = recall(train_true, train_pred) #полнота\n",
    "    f_measure_result = f_measure(train_true, train_pred)\n",
    "    \n",
    "    first_answer = \"Answer: \" + str(\"%.2f\" % accuracy_result) + \" \" + str(\"%.2f\" % precision_result) + \" \" + str(\"%.2f\" % recall_result) +\" \"+ str(\"%.2f\" % f_measure_result)\n",
    "    \n",
    "    print(tp,fp,fn,tn)\n",
    "    \n",
    "    print(first_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n",
      "Answer: 0.54 0.56 0.42 0.48\n"
     ]
    }
   ],
   "source": [
    "first_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_task(): #пункты 5-6 задания\n",
    "    \n",
    "    train = []\n",
    "    with open('scores.csv') as file:\n",
    "        reader = csv.reader(file, delimiter = ',')\n",
    "        for row in reader:\n",
    "            train.append(row)\n",
    "    train = np.array(train)\n",
    "    \n",
    "    train_true = train[1:,0]\n",
    "    train_logreg = train[1:,1]\n",
    "    train_svm = train[1:,2]\n",
    "    train_knn = train[1:,3]\n",
    "    train_tree = train[1:,4]\n",
    "\n",
    "    train_true = [float(i) for i in train_true]\n",
    "    train_logreg = [float(i) for i in train_logreg]\n",
    "    train_svm = [float(i) for i in train_svm]\n",
    "    train_knn = [float(i) for i in train_knn]\n",
    "    train_tree = [float(i) for i in train_tree]\n",
    "    \n",
    "    logreg_result = roc(train_true, train_logreg)\n",
    "    svm_result = roc(train_true, train_svm)\n",
    "    knn_result = roc(train_true, train_knn)\n",
    "    tree_result = roc(train_true, train_tree)\n",
    "    \n",
    "    result = [['score_logreg',logreg_result],['score_svm',svm_result],['score_knn',knn_result],['score_tree',tree_result]]\n",
    "    \n",
    "    max = 0\n",
    "    max_i = -1\n",
    "    for i in range(len(result)):\n",
    "        if result[i][1] > max:\n",
    "            max = result[i][1]\n",
    "            max_i = i\n",
    "            \n",
    "    print(result[max_i][0])\n",
    "    \n",
    "    train = [train_logreg, train_svm, train_knn, train_tree]\n",
    "    \n",
    "    precision_arr = [[],[],[],[]]\n",
    "    recall_arr = [[],[],[],[]]\n",
    "    thresholds_arr = [[],[],[],[]]\n",
    "    for i in range(len(train)):\n",
    "        precision_arr[i], recall_arr[i], thresholds_arr[i] = precision_recall_curve(train_true, train[i])\n",
    "    \n",
    "    \n",
    "    result_prcurve = result\n",
    "    for j in range(len(train)):\n",
    "    \n",
    "        max = 0.7\n",
    "        max_i = -1\n",
    "        for i in range(len(recall_arr[j])):\n",
    "            if recall_arr[j][i] < max:\n",
    "                max_i = i\n",
    "                break\n",
    "        max = 0\n",
    "        for i in range(0,max_i+1):\n",
    "            if precision_arr[0][i] > max:\n",
    "                max = precision_arr[0][i]\n",
    "        result_prcurve[j][1] = max\n",
    "    \n",
    "    max = 0\n",
    "    max_i = -1\n",
    "    for i in range(len(result_prcurve)):\n",
    "        if result_prcurve[i][1] > max:\n",
    "            max = result_prcurve[i][1]\n",
    "            max_i = i\n",
    "            \n",
    "    print(result_prcurve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg\n",
      "[['score_logreg', 0.6302521008403361], ['score_svm', 0.6302521008403361], ['score_knn', 0.5641025641025641], ['score_tree', 0.49746192893401014]]\n"
     ]
    }
   ],
   "source": [
    "second_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
